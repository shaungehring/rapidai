# RapidAI ğŸš€

[![PyPI version](https://badge.fury.io/py/rapidai.svg)](https://pypi.org/project/rapidai/)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**Production-ready Python framework for building AI applications fast**

RapidAI is designed for one thing: getting from idea to deployed AI application in under an hour. When your boss asks you to POC the latest AI tool, this is the framework you reach for.

## Vision

A web framework that bridges the gap between Flask's simplicity and Django's batteries-included approach, but optimized specifically for modern AI development. Think of it as "the Rails of AI apps" - convention over configuration, but for LLM-powered applications.

## âœ¨ Features

- **ğŸ¤– Zero-config LLM integration** - Built-in support for Anthropic Claude, OpenAI, Cohere with unified interface
- **ğŸ“¡ Streaming by default** - SSE/WebSocket streaming built into routes, not bolted on
- **ğŸ”„ Background jobs** - Async task processing with automatic retry and job tracking
- **ğŸ“Š Built-in monitoring** - Token usage, cost tracking, and metrics dashboard
- **ğŸ¨ UI components** - Pre-built chat interfaces with customizable themes
- **ğŸ“š RAG system** - Document loading, embeddings, vector DB integration for retrieval
- **ğŸ“ Prompt management** - Version control and templating for prompts with Jinja2
- **ğŸ’¾ Smart caching** - Semantic caching using embedding similarity
- **ğŸ§ª Testing utilities** - TestClient, MockLLM, MockMemory for easy testing
- **âš¡ CLI tool** - Project templates, dev server, deployment, and more

## ğŸš€ Quick Start

### Simple Chat Endpoint

```python
from rapidai import App, LLM

app = App()
llm = LLM("claude-3-haiku-20240307")

@app.route("/chat", methods=["POST"])
async def chat(message: str):
    response = await llm.complete(message)
    return {"response": response}

if __name__ == "__main__":
    app.run()
```

### With Streaming

```python
from rapidai import App, LLM

app = App()
llm = LLM("claude-3-haiku-20240307")

@app.route("/chat", methods=["POST"])
async def chat(message: str):
    async for chunk in llm.stream(message):
        yield chunk

if __name__ == "__main__":
    app.run()
```

### With Background Jobs

```python
from rapidai import App, background

app = App()

@background(max_retries=3)
async def process_document(doc_id: str):
    # Long-running task runs in background
    await analyze_document(doc_id)

@app.route("/process", methods=["POST"])
async def start_processing(doc_id: str):
    job = await process_document(doc_id)
    return {"job_id": job.id, "status": job.status}
```

### With Monitoring

```python
from rapidai import App, LLM, monitor

app = App()
llm = LLM("claude-3-haiku-20240307")

@app.route("/chat", methods=["POST"])
@monitor()  # Automatically tracks tokens and costs
async def chat(message: str):
    return await llm.complete(message)

@app.route("/metrics")
async def metrics():
    return app.get_metrics_html()  # Built-in dashboard
```

## ğŸ“¦ Installation

```bash
pip install rapidai
```

### Optional Dependencies

Install with specific features:

```bash
# Anthropic Claude support
pip install "rapidai[anthropic]"

# OpenAI support
pip install "rapidai[openai]"

# RAG (document loading, embeddings, vector DB)
pip install "rapidai[rag]"

# Redis (for caching and memory)
pip install "rapidai[redis]"

# Everything
pip install "rapidai[all]"

# Development tools
pip install "rapidai[dev]"
```

## ğŸ“‹ What's Included

### Core Framework

- âœ… **App class** - Fast async web server with routing
- âœ… **LLM clients** - Anthropic Claude, OpenAI, Cohere with unified interface
- âœ… **Streaming** - Built-in SSE support for real-time responses
- âœ… **Memory** - Conversation history (in-memory and Redis)
- âœ… **Caching** - Semantic caching with embedding similarity
- âœ… **Config** - Environment-based configuration with Pydantic

### Advanced Features

- âœ… **Background jobs** - `@background` decorator with retry logic and job tracking
- âœ… **Monitoring** - `@monitor` decorator with token/cost tracking and HTML dashboard
- âœ… **RAG system** - Document loading (PDF, DOCX, TXT, HTML, MD), embeddings, vector DB
- âœ… **Prompt management** - Template-based prompts with Jinja2 and versioning
- âœ… **UI components** - Pre-built chat interfaces with themes and customization
- âœ… **Testing utilities** - TestClient, MockLLM, MockMemory for easy testing

### Developer Tools

- âœ… **CLI tool** - `rapidai new`, `rapidai dev`, `rapidai deploy`, `rapidai test`
- âœ… **Project templates** - Chatbot, RAG, Agent, API templates
- âœ… **Type hints** - Full type coverage for IDE support
- âœ… **Documentation** - Complete guides and API references at [rapidai.dev](https://rapidai.dev)

## Status

**Version:** 1.0.0 - Production Ready ğŸ‰

See [CHANGELOG.md](CHANGELOG.md) for release notes.

## ğŸ’¡ Use Cases

Perfect for building:

- ğŸ¤– **Chat applications** - Customer support bots, AI assistants
- ğŸ“š **RAG systems** - Document Q&A, knowledge bases
- ğŸ”§ **Internal tools** - AI-powered dashboards and workflows
- ğŸ“Š **Data processing** - Background jobs for document analysis
- ğŸŒ **AI APIs** - REST endpoints with LLM integration
- ğŸ¯ **Rapid prototypes** - POCs and MVPs in under an hour

## ğŸ¯ Philosophy

1. **Convention over configuration** - Sensible defaults, minimal boilerplate
2. **Provider agnostic** - Swap OpenAI for Anthropic with one line
3. **Async-first** - Built on modern async/await patterns
4. **Type-safe** - Full type hints for excellent IDE support
5. **Batteries included** - Everything you need, nothing you don't
6. **Production ready** - Monitoring, testing, deployment from day one

## ğŸ“š Documentation

Complete documentation available at **[rapidai.dev](https://rapidai.dev)**

- [Getting Started Guide](https://rapidai.dev/tutorial/intro/)
- [LLM Integration](https://rapidai.dev/advanced/llm/)
- [Background Jobs](https://rapidai.dev/advanced/background/)
- [Monitoring & Metrics](https://rapidai.dev/advanced/monitoring/)
- [RAG System](https://rapidai.dev/advanced/rag/)
- [UI Components](https://rapidai.dev/advanced/ui/)
- [Testing Guide](https://rapidai.dev/advanced/testing/)
- [Deployment](https://rapidai.dev/deployment/overview/)
- [API Reference](https://rapidai.dev/reference/app/)

## ğŸ› ï¸ CLI Tool

RapidAI includes a powerful CLI for project scaffolding and management:

```bash
# Create a new project from template
rapidai new my-chatbot --template chatbot

# Start development server with hot reload
rapidai dev

# Run tests
rapidai test

# Deploy to cloud platforms
rapidai deploy --platform vercel

# Generate documentation
rapidai docs
```

**Available templates:**

- `chatbot` - Simple chat application
- `rag` - RAG system with document Q&A
- `agent` - AI agent with tools
- `api` - REST API with LLM endpoints

## ğŸ‘¨â€ğŸ’» Development

```bash
# Clone the repository
git clone https://github.com/shaungehring/rapidai.git
cd rapidai

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install in editable mode with dev dependencies
pip install -e ".[dev]"

# Install pre-commit hooks
pre-commit install

# Run tests
pytest

# Run tests with coverage
pytest --cov=rapidai tests/

# Type check
mypy rapidai

# Lint and format
ruff check rapidai
ruff format rapidai
```

## ğŸ¤ Community & Support

- ğŸ“– **Documentation** - [rapidai.dev](https://rapidai.dev)
- ğŸ› **Bug Reports** - [GitHub Issues](https://github.com/shaungehring/rapidai/issues)
- ğŸ’¡ **Feature Requests** - [GitHub Discussions](https://github.com/shaungehring/rapidai/discussions)
- ğŸ“¦ **PyPI Package** - [pypi.org/project/rapidai](https://pypi.org/project/rapidai/)
- ğŸ“‹ **Changelog** - [CHANGELOG.md](CHANGELOG.md)

## ğŸš€ Publishing

RapidAI is available on PyPI. To publish a new version:

```bash
# Test on TestPyPI first
./scripts/publish.sh test

# Publish to production PyPI
./scripts/publish.sh prod
```

See [PUBLISHING.md](PUBLISHING.md) for complete publishing guide.

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details.

## ğŸ™ Contributing

We welcome contributions! Whether it's:

- ğŸ› Bug fixes
- âœ¨ New features
- ğŸ“š Documentation improvements
- ğŸ§ª Test coverage
- ğŸ’¡ Ideas and suggestions

See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines on how to contribute.

## â­ Show Your Support

If you find RapidAI helpful, please consider:

- â­ Starring the [GitHub repository](https://github.com/shaungehring/rapidai)
- ğŸ“¢ Sharing with your network
- ğŸ› Reporting issues you encounter
- ğŸ’¡ Suggesting new features

---

Built with â¤ï¸ for AI engineers who move fast

**Version:** 1.0.0 | **Status:** Production Ready ğŸ‰
